{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886019de-735a-4c52-9f2d-0e7f4075570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\gazim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\gazim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\gazim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gazim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gazim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# How to handle Imbalanced Data in machine learning classification\n",
    "# The slides presented are based on the following Tutorial\n",
    "# https://www.justintodata.com/imbalanced-data-machine-learning-classification/\n",
    "# This tutorial will focus on imbalanced data in machine learning for binary classes,\n",
    "# but you could extend the concept to multi-class. \n",
    "!pip install imblearn #install imblearn if not installed before\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b3b187-7dc2-4ede-a4e6-73fd1bd6fcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight     Class  \n",
       "0         0.150  negative  \n",
       "1         0.070  negative  \n",
       "2         0.210  negative  \n",
       "3         0.155  negative  \n",
       "4         0.055  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('abalone19.dat')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc357754-be37-4429-ab5b-de5b0755550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4174 entries, 0 to 4173\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4174 non-null   object \n",
      " 1   Length          4174 non-null   float64\n",
      " 2   Diameter        4174 non-null   float64\n",
      " 3   Height          4174 non-null   float64\n",
      " 4   Whole_weight    4174 non-null   float64\n",
      " 5   Shucked_weight  4174 non-null   float64\n",
      " 6   Viscera_weight  4174 non-null   float64\n",
      " 7   Shell_weight    4174 non-null   float64\n",
      " 8   Class           4174 non-null   object \n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 293.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Find out more about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d1cff3-9990-4af8-9b12-d8d7772cdaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "      <td>4174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.524032</td>\n",
       "      <td>0.407919</td>\n",
       "      <td>0.139524</td>\n",
       "      <td>0.828771</td>\n",
       "      <td>0.359361</td>\n",
       "      <td>0.180607</td>\n",
       "      <td>0.238853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120033</td>\n",
       "      <td>0.099187</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.490065</td>\n",
       "      <td>0.221771</td>\n",
       "      <td>0.109574</td>\n",
       "      <td>0.139143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.442125</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799750</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.501875</td>\n",
       "      <td>0.252875</td>\n",
       "      <td>0.328875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole_weight  Shucked_weight  \\\n",
       "count  4174.000000  4174.000000  4174.000000   4174.000000     4174.000000   \n",
       "mean      0.524032     0.407919     0.139524      0.828771        0.359361   \n",
       "std       0.120033     0.099187     0.041818      0.490065        0.221771   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.442125        0.186500   \n",
       "50%       0.545000     0.425000     0.140000      0.799750        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.501875   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera_weight  Shell_weight  \n",
       "count     4174.000000   4174.000000  \n",
       "mean         0.180607      0.238853  \n",
       "std          0.109574      0.139143  \n",
       "min          0.000500      0.001500  \n",
       "25%          0.093500      0.130000  \n",
       "50%          0.171000      0.234000  \n",
       "75%          0.252875      0.328875  \n",
       "max          0.760000      1.005000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce some stats on the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224b73f4-09be-46f9-9a5c-76c734e6cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "M    1526\n",
       "I    1341\n",
       "F    1307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We’ll use the most basic machine learning classification algorithm: logistic regression. \n",
    "# It is better to convert all the categorical columns for logistic regression to dummy variables. \n",
    "# we’ll convert the categorical columns (Sex and Class) within the dataset before modeling.\n",
    "# Lets look at the category of Sex\n",
    "# Three Classes: Male, Infant and Female\n",
    "\n",
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eb0ad7-db87-4de2-bb3b-7f2a115f6c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "negative    4142\n",
       "positive      32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at the category of Class\n",
    "# Two Classes: Negative and Positive\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74785b6a-f8db-4ff9-b19f-cec68bcdb0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>M</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4174 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4169   M   0.560     0.430   0.155        0.8675          0.4000   \n",
       "4170   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4171   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4172   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4173   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Class  \n",
       "0             0.1010        0.1500      0  \n",
       "1             0.0485        0.0700      0  \n",
       "2             0.1415        0.2100      0  \n",
       "3             0.1140        0.1550      0  \n",
       "4             0.0395        0.0550      0  \n",
       "...              ...           ...    ...  \n",
       "4169          0.1720        0.2290      0  \n",
       "4170          0.2390        0.2490      0  \n",
       "4171          0.2145        0.2605      0  \n",
       "4172          0.2875        0.3080      0  \n",
       "4173          0.2610        0.2960      0  \n",
       "\n",
       "[4174 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us convert the Class label into 0 and 1\n",
    "df['Class'] = df['Class'].map(lambda x: 0 if x == 'negative' else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b9d7db-b05a-4a8d-bdfb-20c44c619dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4174 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4169   0.560     0.430   0.155        0.8675          0.4000          0.1720   \n",
       "4170   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4171   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4172   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4173   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "\n",
       "      Shell_weight  Class  Sex_I  Sex_M  \n",
       "0           0.1500      0  False   True  \n",
       "1           0.0700      0  False   True  \n",
       "2           0.2100      0  False  False  \n",
       "3           0.1550      0  False   True  \n",
       "4           0.0550      0   True  False  \n",
       "...            ...    ...    ...    ...  \n",
       "4169        0.2290      0  False   True  \n",
       "4170        0.2490      0  False  False  \n",
       "4171        0.2605      0  False   True  \n",
       "4172        0.3080      0  False   True  \n",
       "4173        0.2960      0  False  False  \n",
       "\n",
       "[4174 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us convert the Sex feature into two dummy variables\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc39a6a-c854-4481-a7e5-2e69ebc70027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.992333\n",
       "1    0.007667\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3bc4c9-dfb7-450b-9716-0a9263422f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Class'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167342f9-4a9d-4bc3-9219-1cb83cf8906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Training and Testing sets\n",
    "# Let’s split the dataset into training (80%) and test sets (20%). \n",
    "# Use the train_test_split function with stratify argument based on Class categories. \n",
    "# So that both the training and test datasets will have similar portions of classes as # the complete dataset. \n",
    "# This is important for imbalanced data.\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['Class'], random_state=888)\n",
    "\n",
    "features = df_train.drop(columns=['Class']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd237670-9701-4393-883a-108e71bc1750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    3313\n",
       "1      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two sets: df_train and df_test. \n",
    "# We’ll use df_train for modeling, and df_test for evaluation.\n",
    "# Print the different classes (0 and 1) that are present in the Training Set\n",
    "df_train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128871e3-839c-4b72-b3bd-0c77dcc3a84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    829\n",
       "1      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the different classes (0 and 1) that are present in the Testing Set\n",
    "df_test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1152c82-067c-4037-9a5a-5269a5d7b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for this model using the original unbalanced data ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6831523924406916)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us train a Logistic Regression with the unbalanced Data and check the auc\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "features = df_train.drop(columns=['Class']).columns\n",
    "clf.fit(df_train[features], df_train['Class'])\n",
    "\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "print(\"The AUC score for this model using the original unbalanced data ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "080a526b-9b33-4e2b-bc78-d6e462086f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could use the library imbalanced-learn to random oversample.\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "ros = RandomOverSampler(random_state=888)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_train[features], df_train['Class'])\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d0c382-4a8a-46df-837a-cd38604a7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for this model after Random Over Sampling  ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8389626055488542)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then apply Logistic Regression and calculate the AUC metric.\n",
    "clf = LogisticRegression(random_state=888)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "print(\"The AUC score for this model after Random Over Sampling  ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de0c73bb-0391-4ac4-947c-a0ec7533be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling using SMOTE ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random sampling is easy, but the new samples don’t add more information. \n",
    "# SMOTE improves on that. \n",
    "# SMOTE oversamples the minority class by creating ‘synthetic’ examples.\n",
    "# It involves some methods (nearest neighbors), to generate plausible examples.\n",
    "print(\"Oversampling using SMOTE ...\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=888)\n",
    "X_resampled, y_resampled = smote.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee965223-ddee-443a-aaf5-640206b90894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for this model after SMOTE ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8564535585042219)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We’ll apply logistic regression on the balanced dataset and calculate its AUC.\n",
    "\n",
    "clf = LogisticRegression(random_state=888)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "print(\"The AUC score for this model after SMOTE ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93c6279-770d-43fc-a382-4a65742c2ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    26\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will use Undersampling\n",
    "# Undersampling, we will downsize majority class to balance with the minority class.\n",
    "# Simple random undersampling\n",
    "# We’ll begin with simple random undersampling. \n",
    "rus = RandomUnderSampler(random_state=888)\n",
    "X_resampled, y_resampled = rus.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f745491f-4fdc-46a7-9c81-af542f9c32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for this model after Under Sampling ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6467631684760756)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And this produces the same AUC as pandas undersampling, since we use the same\n",
    "clf = LogisticRegression(random_state=888)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "print(\"The AUC score for this model after Under Sampling ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbad9ab0-69c7-4b4e-b517-650da61b910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    26\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampling using K-Means\n",
    "# Besides random sampling, we could also use the cluster centroid of \n",
    "# the K-Means method as the new sample of the majority class. \n",
    "\n",
    "cc = ClusterCentroids(random_state=888)\n",
    "X_resampled, y_resampled = cc.fit_resample(df_train[features], df_train['Class'])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "234e64a8-8a36-4504-95c6-7c8e416b8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for this model after using K-Means ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.732810615199035)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Logistic Regression on the new dataset that is undersampled using K-Means\n",
    "clf = LogisticRegression(random_state=888)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "print(\"The AUC score for this model after using K-Means ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ba471c7-5e67-4cd7-aaa3-d581d0910aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we want the dataset to be balanced, we need the following weights for Majority vs Minority ..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.50392394, 64.21153846])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighing classes differently\n",
    "# We can also balance the classes by weighing the data differently\n",
    "# We usually consider each observation equally, with a weight value of 1\n",
    "# But for imbalanced datasets, we can balance the classes by putting more weight   # on the minority classes.\n",
    "# The below code estimates weights for our imbalanced training dataset.\n",
    "\n",
    "weights = compute_class_weight('balanced', classes=df_train['Class'].unique(), y=df_train['Class'])\n",
    "print(\"If we want the dataset to be balanced, we need the following weights for Majority vs Minority ..\")\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "537625aa-56f6-43ac-ac6a-6b992b8e9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing the following re-wieghting of classes we get ..\n",
      "1669.5\n",
      "1669.5000000000002\n"
     ]
    }
   ],
   "source": [
    "# Let’s verify that these weights can indeed balance the dataset.\n",
    "# Multiply the counts of each class by their respective weights.\n",
    "\n",
    "print(\"Performing the following re-wieghting of classes we get ..\")\n",
    "print((df_train['Class'] == 0).sum()*weights[0])\n",
    "print((df_train['Class'] == 1).sum()*weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78653ed6-f4ac-4178-b70f-eeb5d8cb44da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339.0\n",
      "3339\n"
     ]
    }
   ],
   "source": [
    "# If we sum up the weights of both classes,\n",
    "# it is equivalent to if we just weight each data by 1.\n",
    "print((df_train['Class'] == 0).sum()*weights[0] + (df_train['Class'] == 1).sum()*weights[1])\n",
    "print((df_train['Class'] == 0).sum() + (df_train['Class'] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "618aa69c-9364-4a0a-8d5d-709221f8a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score after using Weighted Logistic Regression (balanced) ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8260956976276639)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All right! So now you’ve got the idea of how to weigh classes differently.\n",
    "# What does this mean for a machine learning algorithm like logistic regression?\n",
    "# Different weights make it cost more to misclassify a minority than majority class\n",
    "# We can use code below to apply LR to the differently weighted datasets,\n",
    "# with the extra argument class_weight='balanced’.\n",
    "\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=888)\n",
    "clf_weighted.fit(df_train[features], df_train['Class'])\n",
    "\n",
    "y_pred = clf_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "print(\"The AUC score after using Weighted Logistic Regression (balanced) ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e77f9c4-1403-4220-b245-f1bfe945976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score after using Weighted Logistic Regresion (weighted) ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8373542420587052)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Besides changing the weights of the two classes to balance them, \n",
    "# We can also specify custom weights of positive and negative classes\n",
    "# For example, the below code weighs class 1 by 100 times more than class 0.\n",
    "\n",
    "clf_weighted = LogisticRegression(class_weight={0: 1, 1: 100}, random_state=888)\n",
    "\n",
    "clf_weighted.fit(df_train[features], df_train['Class'])\n",
    "y_pred = clf_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "print(\"The AUC score after using Weighted Logistic Regresion (weighted) ...\")\n",
    "roc_auc_score(df_test['Class'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a9d49-20cd-4a94-b5e5-bed8afce59fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
